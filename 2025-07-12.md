## 시스템 흐름

1. **카메라 파라미터 및 데이터 경로 지정**
    
    [config.py](attachment:3fba2b45-6b1e-4f81-af75-c7bd52a75989:config.py)
    
2. **입력 데이터의 키포인트 라벨을 기반으로 2D좌표 추출**
    
    - `trajectories_raw`: 객체 ID를 키로, 프레임별 3D 좌표 리스트 값 딕셔너리
    
    [label_to_2Dcoordinate.py](attachment:6360f6b6-d874-4a08-a36e-385929ee8094:label_to_2Dcoordinate.py)
    
3. **2D 좌표 → 3D 좌표 변환**
    
    - `coords_3d`: `(X, Y, Z)` 3D 좌표 튜플
    
    [Shift_3Dcoordinate.py](attachment:559f6e2a-4cba-4507-8c5b-7e528cf2ca36:Shift_3Dcoordinate.py)
    
4. **개체별 거리/고도/깊이 추출**
    
    - `bbox`: 2D 바운딩 박스
    
    [dist_alt_estimation.py](attachment:3f8a8b23-1b63-425b-9194-97d5adb924e8:dist_alt_estimation.py)
    
5. **Kalman filter 기반 개체간 트래킹**
    
    - `smooth_path`: 칼만 필터로 스무딩한 고니의 3D 좌표 시퀀스 (리스트)
    
    [kalman_tracker.py](attachment:be1339d5-083e-4619-8494-bc909cf1d625:kalman_tracker.py)
    
    - 속도와 방향 기반으로 다음 개체 위치 예측
    - 첫 프레임과 두번째 프레임만 유클리드 거리를 기반으로 트래킹
6. **속력, 방향 벡터 산출**
    
    [vector_calculator.py](attachment:2091de91-8896-4a35-acd6-f93f7e2905e9:vector_calculator.py)
    
7. **도약 거리 및 각도 산출**
    
    - `takeoff_info`: 이륙 각도 등 분석 정보 딕셔너리
    
    [flight_analyzer.py](attachment:b9c02352-5eef-40d9-8180-a790cc8e2503:flight_analyzer.py)
    
8. **개체별 누적 소비 에너지량 산출**
    
    - `total_energy`: 총 소비 에너지 (Joule)
    
    [energy_calculator.py](attachment:5efa2544-6b01-4187-b8c5-a59aeb20b72b:energy_calculator.py)
    
9. **개체별 정보 엑셀 파일 생성**
    
    [swan_data_exporter.py](attachment:4590364f-a6f6-4106-a8de-9d64a3b98c78:swan_data_exporter.py)
    
    - 2D좌표/3D좌표/거리/고도/깊이/속력/방향 벡터

**→ 1 - 9 단계를 `full_swan_analysis_pipeline.py` 메인 스크립트로 실행**

1. **9단계에서 생성한 엑셀 파일을 입력으로 프레임별 데이터 시각화(+그래프), 영상 출력**
    
    [visual.py](attachment:82c169a5-7a24-44c1-8949-5ea71cc6b728:visual.py)
    
2. **영상 출력을 보고 인간이 직접 수치 조정, 재출력 → 해당 과정 반복**
    

---

![엑셀 출력물](attachment:73794be3-6e50-4910-9114-0fdf341034aa:%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-07-10_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_4.41.57.png)

엑셀 출력물

# 모듈별 작동 원리 및 과정

## 3D 좌표 추출

## 2D 키포인트 기반 3D 좌표 변환 방법론

### 1. 개요

- 단일 카메라 영상에서 탐지된 객체의 **2D 키포인트(Keypoint) 좌표**와 **실제 세계 크기 정보**를 활용하여, 해당 객체의 **3D 공간 좌표(X, Y, Z)를 추정**하는 방법론을 기술
- 핵심은 카메라 투영 모델과 유사 삼각형 원리를 이용해 객체까지의 깊이(거리)를 계산하는것

---

### 2. 핵심 원리

카메라에 맺히는 물체의 크기는 카메라로부터의 거리에 반비례

→ 따라서 객체의 실제 크기와 이미지에 투영된 픽셀 크기를 알고 있다면, 삼각비 원리를 통해 카메라와 객체 사이의 거리, 즉 **깊이(`Z`)**를 역산 가능

`깊이(Z) = (객체의 실제 크기 × 렌즈 초점 거리) / 이미지 속 객체의 픽셀 크기`

깊이(`Z`) 값이 확정되면, 핀홀 카메라 모델의 기본 공식을 사용하여 나머지 3D 좌표 `X`와 `Y`를 계산 가능

---

### 3. 변환 절차

변환 과정은 제공된 `Shift_3Dcoordinate.py` 코드에 따라 다음 4단계로 진행

1. **2D 키포인트 추출**
    
    : YOLOv8 라벨 파일(`.txt`)의 텍스트 한 줄을 읽어, 정규화된 좌표를 이미지의 실제 픽셀 좌표로 변환하여 7개의 2D 키포인트 위치를 확보합니다.
    
2. **이미지상 크기 계산**
    
    : 추출된 키포인트들을 이용해 새의 날개폭에 해당하는 길이를 픽셀(px) 단위로 계산합니다.
    
3. **렌즈 왜곡 보정**
    
    : 정확도를 높이기 위해, 미리 정의된 왜곡 계수(`DIST_COEFFS`)를 사용하여 기준점(몸통)의 2D 좌표를 보정
    
4. **깊이(Z) 및 3D 좌표(X, Y) 산출**: '핵심 원리'의 공식을 사용하여 깊이(`Z`)를 계산한 뒤, 이를 바탕으로 최종 3D 좌표 `X`와 `Y`를 산출
    

---

## **비행 에너지 산출**

[energy_calculator.py](attachment:536a4c9c-cabd-4275-8d67-08cb5f0296b3:energy_calculator.py)

### **1. 주요 변수 정의**

- **질량 (m)**: 대상 객체의 무게. (본 프로젝트의 고니는 **10kg**으로 가정)
    
- **중력가속도 (g)**: 9.8m/s2
    
- **위치 벡터 (pi)**: 특정 시점 `i`에서의 객체의 3차원 위치 [xi,yi,zi]. 단위는 미터(m).
    
    [](data:image/svg+xml;utf8,<svg xmlns="[http://www.w3.org/2000/svg](http://www.w3.org/2000/svg)" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5%0A3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11%0A10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63%0A-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1%0A-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59%0AH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359%0Ac-16-25.333-24-45-24-59z"></path></svg>)
    
- **속도 벡터 (vi)**: 특정 시점 `i`에서의 객체의 3차원 속도. 단위는 m/s.
    
    [](data:image/svg+xml;utf8,<svg xmlns="[http://www.w3.org/2000/svg](http://www.w3.org/2000/svg)" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5%0A3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11%0A10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63%0A-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1%0A-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59%0AH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359%0Ac-16-25.333-24-45-24-59z"></path></svg>)
    
- **시간 간격 (dt)**: 데이터가 측정된 시간 간격. (예: 1/30초)
    
    ---
    

### **2. 주요 변수 정의**

→ 에너지 산출에 사용되는 주요 물리 변수

- **질량 (`$m$`)**: 대상 객체의 무게. (본 프로젝트의 고니는 **10kg**으로 가정)
- **중력가속도 (`$g$`)**: `$9.8 \\, m/s^2$`
- **위치 벡터 (`$\\vec{p}_i$`)**: 특정 시점 `$i$`에서의 객체의 3차원 위치 `$[x_i, y_i, z_i]$`. 단위는 미터(m).
- **속도 벡터 (`$\\vec{v}_i$`)**: 특정 시점 `$i$`에서의 객체의 3차원 속도. 단위는 `$m/s$`.
- **시간 간격 (`$dt$`)**: 데이터가 측정된 시간 간격 (초).

### **3. 계산 원리**

객체가 한 지점(`$\\vec{p}_i$`)에서 다음 지점(`$\\vec{p}_{i+1}$`)으로 이동하는 데 필요한 에너지(일, `$W$`)는 객체의 총 역학적 에너지(`$E$`)의 변화량과 같음

→ 총 역학적 에너지는 운동 에너지(`$E_k$`)와 위치 에너지(`$E_p$`)의 합으로 정의

$W_{i \to i+1} = \Delta E = \Delta E_k + \Delta E_p$

- 운동 에너지 (Kinetic Energy, $E_k$)
    
    객체의 속력과 관련된 에너지로, 속도 벡터($\vec{v}$)의 크기($v = ||\vec{v}||$)를 이용해 계산합니다.
    
    $E_k = \frac{1}{2}mv^2$
    
- 위치 에너지 (Potential Energy, $E_p$)
    
    객체의 고도와 관련된 에너지로, 위치 벡터의 Y축 성분($h = y$)을 높이로 사용합니다.
    
    $E_p = mgh$
    

따라서 한 구간에서 소비된 총에너지는 각 에너지의 변화량을 더한 값

$W_{i \to i+1} = \left( \frac{1}{2}mv_{i+1}^2 - \frac{1}{2}mv_i^2 \right) + (mgh_{i+1} - mgh_i)$

---

### **4. 계산 절차**

1. **데이터 수집**: 추적 대상(ID)별로 시간 순서에 따른 3D 위치 데이터 `$\\vec{p}_0, \\vec{p}_1, \\vec{p}_2, \\dots$`를 확보
    
2. 속도 벡터 계산
    
    : 연속된 위치 데이터와 시간 간격($dt$)을 이용하여 각 시점의 속도 벡터($\vec{v}_i$)를 계산
    
    $\vec{v}_i = \frac{\vec{p}_{i+1} - \vec{p}_i}{dt}$
    
3. **구간별 에너지 계산**
    
    : 모든 이동 구간(`$i \\to i+1$`)에 대해 3번 섹션의 공식을 적용하여 운동 에너지 변화량(`$\\Delta E_k$`)과 위치 에너지 변화량(`$\\Delta E_p$`)을 구한 뒤, 이를 합산하여 해당 구간의 총에너지 변화량(`$W$`)을 산출
    
4. **총 누적 에너지 산출**
    
    : 생물학적 에너지 소비는 항상 양수(+)의 값을 가짐 → 따라서 물리적으로 계산된 일(`$W$`)의 값 중, 객체가 외부의 힘에 저항하여 스스로 에너지를 생성해야 하는 경우(가속 및 상승)에 해당하는 양수(+)의 값들만 합산
    
    → 이를 통해 비행에 필요한 최소한의 누적 소비 에너지를 추정
    

## **칼만 필터 3D 객체 추적**

[3D Kalman filter tracking(실험중)](https://www.notion.so/3D-Kalman-filter-tracking-22bec508cf3c80169c9dd28a98ddf059?pvs=21)

![image.png](attachment:0f880752-a97d-4f2b-81ed-dc7bb31b6007:569b8da6-5a55-4b9b-afda-6bc6be867f8d.png)

## **1. 칼만 필터 모델 정의**

본 프로젝트의 3D 객체 추적을 위한 칼만 필터 모델은 다음과 같이 정의

- **상태 벡터 (State Vector, $\vec{x}$)**
    
    추적하고자 하는 객체의 상태를 나타내며, 3차원 위치($x, y, z$)와 3차원 속도($v_x, v_y, v_z$)로 구성된 6차원 벡터이다.
    
    $\vec{x} = [x, y, z, v_x, v_y, v_z]^T$
    
- **측정 벡터 (Measurement Vector, $\vec{z}$)**
    
    각 프레임에서 센서(카메라)를 통해 직접 측정되는 값으로, 객체의 3차원 위치($x, y, z$)
    
    $\vec{z} = [x, y, z]^T$
    
- **상태 변환 모델 (State Transition Model)**
    
    이전 시점($k-1$)의 상태 벡터가 현재 시점($k$)의 상태 벡터로 어떻게 변하는지를 나타내는 물리 모델
    
    → 등속도 모델을 가정
    
    $\vec{x}_k = F \vec{x}_{k-1} + \vec{w}_{k-1}$
    
    ($F$는 상태 변환 행렬, $\vec{w}$는 프로세스 노이즈)
    
- **측정 모델 (Measurement Model)**
    
    현재 상태($\vec{x}_k$)와 측정값($\vec{z}_k$) 사이의 관계를 정의한다. 상태 벡터에서 위치 정보만 측정할 수 있다.
    
    $\vec{z}_k = H \vec{x}_k + \vec{v}_k$
    
    ($H$는 측정 행렬, $\vec{v}$는 측정 노이즈)
    

### **2. 구현 파라미터**

OpenCV의 `cv2.KalmanFilter`를 사용하여 모델을 구현할 때, 핵심 행렬들은 다음과 같이 설정

- 상태 변환 행렬 (State Transition Matrix, $F$)
    
    $dt$ 시간 후의 위치는 $p_{k-1} + v_{k-1} \cdot dt$가 되고, 속도는 변하지 않는다고 가정
    
    $F = \begin{bmatrix} 1 & 0 & 0 & dt & 0 & 0 \\ 0 & 1 & 0 & 0 & dt & 0 \\ 0 & 0 & 1 & 0 & 0 & dt \\ 0 & 0 & 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 & 0 & 1 \end{bmatrix}$
    
    [](data:image/svg+xml;utf8,<svg xmlns="[http://www.w3.org/2000/svg](http://www.w3.org/2000/svg)" width="0.667em" height="7.200em" viewBox="0 0 667 7200"><path d="M403 1759 V84 H666 V0 H319 V1759 v3600 v1759 h347 v-84%0AH403z M403 1759 V0 H319 V1759 v3600 v1759 h84z"></path></svg>)
    
    [](data:image/svg+xml;utf8,<svg xmlns="[http://www.w3.org/2000/svg](http://www.w3.org/2000/svg)" width="0.667em" height="7.200em" viewBox="0 0 667 7200"><path d="M347 1759 V0 H0 V84 H263 V1759 v3600 v1759 H0 v84 H347z%0AM347 1759 V0 H263 V1759 v3600 v1759 h84z"></path></svg>)
    
- 측정 행렬 (Measurement Matrix, $H$)
    
    $H = \begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 0 & 0 \end{bmatrix}$
    
    6차원의 상태 벡터 중, 앞의 3개 값(위치)만 측정값과 관련이 있음을 나타냄
    

[](data:image/svg+xml;utf8,<svg xmlns="[http://www.w3.org/2000/svg](http://www.w3.org/2000/svg)" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M403 1759 V84 H666 V0 H319 V1759 v0 v1759 h347 v-84%0AH403z M403 1759 V0 H319 V1759 v0 v1759 h84z"></path></svg>)

[](data:image/svg+xml;utf8,<svg xmlns="[http://www.w3.org/2000/svg](http://www.w3.org/2000/svg)" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M347 1759 V0 H0 V84 H263 V1759 v0 v1759 H0 v84 H347z%0AM347 1759 V0 H263 V1759 v0 v1759 h84z"></path></svg>)

- 노이즈 공분산 행렬 ($Q, R$)
    
    프로세스 노이즈($Q$)와 측정 노이즈($R$)는 필터의 성능을 결정하는 튜닝 파라미터
    
    → $Q$가 작을수록 모델의 예측을 더 신뢰하고, $R$이 작을수록 실제 측정값을 더 신뢰하게 된다.
    

---

**4. 추적 절차**

추적은 초기화, 예측, 보정의 3단계를 재귀적으로 반복하며 수행된다.

1. **초기화 (Initialization)**
    
    : 첫 번째 측정된 3D 위치(`$\\vec{z}_0$`)로 필터의 초기 상태(`$\\vec{x}_0$`)를 설정한다. 이때 초기 속도는 0으로 가정
    
2. **예측 (Prediction)**
    
    : 이전 시점의 상태(`$\\vec{x}_{k-1}$`)와 상태 변환 모델을 사용하여 현재 시점의 상태(`$\\hat{x}_k^-$`)를 예측
    
3. **보정 (Correction/Update)**
    
    : 새로운 측정값(`$\\vec{z}_k$`)이 들어오면, 예측된 상태(`$\\hat{x}_k^-$`)와 실제 측정값 사이의 오차를 보정하여 최종 상태(`$\\hat{x}_k$`)를 추정
    
    → 이 과정에서 **Kalman Gain**이 예측과 측정 중 어느 쪽에 더 비중을 둘지 결정하는 최적의 가중치 역할
    
4. **반복 (Iteration)**
    
    : 모든 프레임에 대해 2번(예측)과 3번(보정) 단계를 반복하여 객체의 전체 경로를 추적
    

---

![스크린샷 2025-07-10 오전 3.19.29.png](attachment:fd27fbdb-12b7-4010-9134-64dcd25d101a:%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-07-10_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_3.19.29.png)

## 이륙 기준점 및 이륙 각도 산출

[flight_analyzer.py](attachment:6f3bb106-86cc-406e-9e25-d08f5887488b:flight_analyzer.py)

---

### **주요 변수**

- **이동 벡터 (Movement Vector, `$\\vec{v}$`)**
    
    : 연속된 두 위치 벡터의 차이 `$\\vec{v}_i = \\vec{p}_{i+1} - \\vec{p}_i$`
    
- **비행 각도 (Flight Angle, `$\\theta$`)**
    
    : 이동 벡터 `$\\vec{v} = [v_x, v_y, v_z]$`가 수평면(XZ 평면)과 이루는 각도
    
    → 수직 변위(`$v_y$`)와 수평 변위(`$\\sqrt{v_x^2 + v_z^2}$`)의 삼각비를 이용하여 계산
    

---

### **계산 원리 및 순서**

**비행 각도 산출 → 각도 변화량 분석 → 이륙 지점 및 각도 확정**

1. **구간별 이동 벡터 계산**
    
    - 시간 순서에 따라 기록된 3D 위치(`$\\vec{p}_0, \\vec{p}_1, \\dots$`) 데이터로부터 각 구간의 이동 벡터(`$\\vec{v}_0, \\vec{v}_1, \\dots$`)를 계산
2. **비행 각도 산출**
    
    - 모든 이동 벡터 `$\\vec{v}$`에 대해 수평면 대비 비행 각도 `$\\theta$`를 계산
    - 수평 이동 거리를 `$d_h = \\sqrt{v_x^2 + v_z^2}$` , 수직 이동 거리를 `$d_v = v_y$`라 할 때, 각도는 다음과 같음 `\\theta = \\arctan\\left(\\frac{d_v}{d_h}\\right)` 이 과정을 통해 비행 경로 전체의 구간별 비행 각도 시퀀스(`$\\theta_0, \\theta_1, \\dots$`)를 확보한다.
3. **이륙 지점 식별**
    
    - 이륙은 비행 각도가 가장 급격하게 증가하는 지점으로 정의
        
    - 연속된 비행 각도 간의 변화량(`$\\Delta\\theta$`)을 계산 `$\\Delta\\theta_i = \\theta_{i+1} - \\theta_i$`
        
    - 각도 변화량(`$\\Delta\\theta_i$`)이 최대가 되는 지점 `$i$`를 '이륙 준비가 완료된 시점'으로 정의
        
        → 따라서 실제 이륙이 시작되는 물리적 위치는 `$\\vec{p}_{i+1}`
        
4. **최종 이륙 각도 정의**
    
    - 각도 변화량이 최대였던 구간, 즉 벡터 `$\\vec{v}_{i+1}$`의 비행 각도인 `$\\theta_{i+1}$`

---

## 속력 및 방향 벡터 산출

[vector_calculator.py](attachment:9501ddc5-d0d9-4894-a72a-44d79943abf7:vector_calculator.py)

## 거리 / 고도 산출

[dist_alt_estimation.py](attachment:737ef771-5d51-49ea-bc37-64bedeb12511:dist_alt_estimation.py)

1. **YOLO 데이터 파싱 (`_parse_yolov8_data` 함수)**
    - YOLO 라벨 파일의 위치 정보 입력
    - 텍스트에서 바운딩 박스와 7개의 키포인트 좌표를 추출하여 프로그램이 사용할 수 있는 숫자(픽셀) 좌표로 변환
2. **픽셀 날개폭 계산 (`_calc_wingspan_px` 함수)**
    - 이미지에 나타난 백조의 날개 관련 키포인트(어깨, 끝)들을 연결하여 픽셀 단위의 날개 길이를 계산
3. **3D 위치 추정 (`BirdPositionEstimator` 클래스)**
    - `estimate_from_line` 메서드가 핵심적인 역할을 수행
    - 라벨 데이터를 파싱 → 이미지상의 픽셀 날개폭을 계산
    - **삼각 측량 원리**를 이용해 카메라로부터 객체까지의 깊이(거리, Z축)를 계산
        - `Z=(실제날개폭 × 카메라초점거리)/픽셀날개폭`
    - 계산된 깊이(Z)와 왜곡 보정된 키포인트 좌표를 이용해 `실제 공간의 좌우 위치(X축)와 고도(Y축)`를 계산

---

[분배](https://www.notion.so/22dec508cf3c8016ac87f107610a7603?pvs=21)