[베리어프리](https://www.autoeverapp.kr/)
![[베리어프리.png]]


## 팀 정보

- **팀명**: 도파민중독자
- **팀원** : 하가형, 손준서, 김경민 
- **아이디어명**: 발화(전면 카메라 기반 아이트래킹 입력과 ‘시선-단어 매핑’ TTS·진동 출력을 결합한 소통 보조 도구)
- **운영체제**: 안드로이드, iOS
- **응모분야**: 자유주제 – 사회취약계층 ‘이동 및 생활 편의 증진’ 앱
    
## 공공정보 활용 여부
- **AIHub 데이터셋 활용**
    1. 디스플레이 중심 안구 움직임 영상 데이터
    2. 안구 움직임 영상 데이터
        
## 아이디어 개요

농아는 모태에서부터 청력을 갖지 못해 언어를 익히지 못한 선천적 농아와, 어린 시절 뇌막염·성홍열 등 후유증으로 청력을 잃어 언어 발달이 멈춘 후천적 농아로 나뉜다. 두 경우 모두 ‘청각장애인’이라는 표현으로 통칭할 수 있지만, 중요한 점은 귀가 들리지 않는다는 사실이 곧 발화(말하기) 능력의 제약으로 이어진다는 것이다.

우리가 유아기에 “꼬끼오!”라며 닭 울음소리를 흉내 내고 “엄마”, “아빠”를 따라할 수 있었던 이유는, 주변의 소리를 듣고 스스로 발음을 교정하는 과정을 거쳤기 때문이다. 반면 청각장애인은 자신이 내는 소리를 들을 수 없으므로 발음을 수정할 기반이 없다. 이 때문에 그들과 대화해 보면 말소리가 어눌하거나 왜곡되어 들리는 경우가 많고, 듣지 못함과 말하지 못함이 겹쳐 소통 장벽이 두 배로 높아진다.

보건복지부가 발표한 2023년 등록장애인 통계는 이러한 현실을 수치로 확인해 준다. 즉, 청각장애인은 전체 장애 인구에서 두 번째로 큰 비중을 차지하며, 특히 장애인 신규 등록과 고령화 추세에서 빠르게 늘고 있다. 이러한 수치는 복지관·주간보호센터 등 현장에서 즉각적이고 직접적인 의사소통 지원이 시급하다는 점을 보여 준다.

‘발화’ 앱은 전면 카메라 기반 아이트래킹 입력과 ‘시선-단어 매핑’ TTS·진동 출력을 결합한 소통 보조 도구이다. 청각장애인은 앱 화면에 보이는 카드를 눈동자로 가리키는 것만으로 내용을 즉시 음성으로 재생해 주변 사람에게 의사를 명확히 전달할 수 있다. 앱 기획 단계에서 우리는 장애인 다누리 주간보호센터와 충주시장애인복지관을 방문해 제4급 1호(양쪽 귀 평균 청력손실 ≥ 70 dB HL), 제3급(≥ 80 dB HL) 청각장애인, 거동이 불편한 장애인, 사회복지사를 대상으로 심층 인터뷰를 진행했다.

현장 인터뷰 결과
- 첫 방문 시 수어 통역·문자 안내 부족으로 초기 상담 어려움    
- 도움 요청을 음성으로 표현하지 못해 큰 답답함
- 복잡한 메뉴 구성·불명확한 안내 음성으로 서비스 접근 지연
- 사회복지사의 한정된 인력으로 다양한 장애 특성 지원에 상담 지연
- 반복 안내로 인력 업무 부담 증가
    

## 개발 계획

- **8월 1주차**
    
    - 역할 선택 화면 구성
        
    - 선택값 저장 및 분기 처리
        
    - 이름 입력 UI 구성
        
    - ERD 확정 및 테이블 설계
        
- **8월 2주차**
    
    - 사용자 고유 ID 자동 생성
        
    - 클라이언트-사용자 매핑 기본 구조 설정
        
    - TTS 옵션 목록 로드 및 선택 UI
        
    - ORM 및 마이그레이션 반영
        
- **8월 3주차**
    
    - 선택 TTS로 미리듣기 테스트 구현
        
    - gaze tracking 연동
        
- **8월 4주차**
    
    - dwell time 로직 구현
        
    - 카드 선택 → TTS 연결
        
- **9월 1주차**
    
    - TTS 출력 반복 및 로그 저장
        
    - order_index 기반 카드 정렬
        
- **9월 2주차**
    
    - layout_mode 별 카드 수 계산 및 렌더
        
- **9월 3주차**
    
    - 카드 텍스트 입력 UI 구성
        
    - 카드 저장 및 order_index 자동 부여
        
- **9월 4주차**
    
    - 환자 고유번호 입력
        
    - 생년월일, 성별, 사진 등록
        
- **10월 1주차**
    
    - 메모 입력 및 저장
        
    - 수정 화면 및 삭제 버튼 구현
        
    - 전체 알림 로그 조회
        
- **10월 2주차**
    
    - 알림 상태(확인/미확인) 표시
        
- **10월 3주차**
    
    - 사용자 선택 후 InteractionLog 필터링 UI
        
- **10월 4주차**
    
    - 사용자별 알림 수 시각화
        
- **11월 1주차**
    
    - 미확인 알림 강조 및 정렬 우선
        
- **11월 2주차**
    
    - TTS 실패, 응시 오류 예외 처리
        
- **11월 3주차**
    
    - 로컬 및 클라우드 저장 동기화 확인
        
- **11월 4주차 ~ 12월 1주차**
    
    - 전체 흐름 QA
        
    - 최종 회고 및 앱 릴리스 준비
        
- **12월 2주차**
    
    - 릴리스 이후 초기 피드백 수집
        
    - QA 회고 정리 및 패치 리스트 작성
        
- **12월 3주차**
    
    - 치명적 버그 수정
        
    - 기능 보완 또는 삭제 검토
        
- **12월 4주차**
    
    - 문서 정리 (기획서, 기능명세서, ERD 최신화)
    - 유지보수 계획 정리
        
- **12월 5주차 (12/29~12/31)**
    - 최종 코드 백업 및 배포 종료
    - 프로젝트 회고 및 정식 마감
        

## 세부내용(주요 기능 및 서비스)

- **정밀 시선 인식 엔진**
    - AI-Hub 안구 영상 데이터(L2CS-Net, RIT-Net) 활용
    - 평균 시선 각도 오차 4° 이하 달성
        
- **시선-단어 매핑 보드*
    - 화면에 큼직한 카드(8–12개) 배치
    - 응시만으로 해당 문구 즉시 TTS 출력
    - 진동 피드백으로 인식 여부 확인
        
- **긴급 호출 모드**
    - ‘SOS’ 카드 2초 응시 시 반복 음성 경보·화면 점멸
    - 직원 단말(워치·태블릿)에 푸시 알림 전송
        
- **자동 화면 최적화**
    - 저조도·역광·안경 착용 상황 대응
    - 실내 조도·시력 잔존도에 맞춘 밝기·글꼴·간격 자동 조정
- **오프라인 핵심 기능**
    - 경량 ONNX 모델과 내장 TTS(11 MB)로 네트워크 불안정 환경에서도 사용 가능
- **개인 맞춤 시선 보정**
    - 초기 10초 교정 절차로 개인 편차 저장 및 정확도 향상
- **상담 로그·통계 대시보드**
    - 카드 사용 빈도·도움 요청 이벤트 익명 집계
    - 서비스 개선·인력 배치 최적화 자료 활용
        

## 기대 효과
- 데이터 기반 운영: 카드 사용·상태 로그 분석으로 서비스 개선 주기를 연 1회 → 분기별로 단축
- 장애인 자립도 증진: 직접·즉각적 도움 요청 채널 제공으로 이용자 자율 활동 범위 확대
- 청각장애인의 소통 자율성 향상: 비접촉·비음성 환경에서 스스로 의사 표현 가능
- 사회복지사 업무 부담 완화: 반복 설명 없이 앱 통해 문장 선택·표현 가능 → 상담 효율 및 인력 활용성 증대
- 직관적 인터페이스로 접근성 강화: 무접촉 인터랙션 방식은 청각장애·거동 불편 중복장애인에게도 유용
- 현장 적용성 검증: 복지관·주간보호센터 피드백 반영 개발 → 실효성 높은 기술 제공
    

## 목표 달성 및 홍보 계획
- **핵심 지표 (2025년 12월까지)**
    - 시선 인식 오차 ≤ 4°
    - SOS 호출 지연 ≤ 3초
    - 초기 상담 시간 단축
        
- **1차 현장 테스트 (2025년 10~11월)**
    - 장애인 다누리 주간보호센터·충주시장애인복지관 20명 대상 4주 진행
    - 주 1회 오류 로그·설문 분석 후 UI·TTS 즉시 개선
        
- **2차 베타 테스트 (2025년 11~12월)**
    - 건국대 글로컬캠퍼스 중앙동아리 LEO, 로타랙트, 뉴라이프 협업
    - 충주 지역 복지센터 3곳에서 설치 지원·교육·운영 데이터 검증
- **무상 배포 (2026년 상반기)**
    - 플레이스토어·앱스토어에 앱 무상 배포