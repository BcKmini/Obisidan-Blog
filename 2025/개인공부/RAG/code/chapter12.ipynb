{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ### 4. 싱글 패스 플랜 제너레이터 (Single-Path Plan Generator)\n",
    "\n",
    "# @markdown 설정된 목표를 달성하기 위한 일련의 구체적인 단계를 생성하는 패턴입니다.\n",
    "\n",
    "# @markdown LangGraph를 이용하여 목표 설정, 태스크 분해, 태스크 실행, 결과 정리의 워크플로우를 구현합니다.\n",
    "\n",
    "\n",
    "# SinglePathPlanGenerationState 스테이트 모델 정의\n",
    "\n",
    "class SinglePathPlanGenerationState(BaseModel):\n",
    "\n",
    "    query: str = Field(..., description=\"사용자가 입력한 쿼리\")\n",
    "\n",
    "    optimized_goal: str = Field(default=\"\", description=\"최적화된 목표\")\n",
    "\n",
    "    optimized_response: str = Field(default=\"\", description=\"최적화된 응답 정의\")\n",
    "\n",
    "    tasks: List[str] = Field(default_factory=list, description=\"실행할 태스크 리스트\")\n",
    "\n",
    "    current_task_index: int = Field(default=0, description=\"현재 실행 중인 태스크 번호\")\n",
    "\n",
    "    results: Annotated[List[str], operator.add] = Field(\n",
    "\n",
    "        default_factory=list, description=\"실행 완료된 태스크 결과 리스트\"\n",
    "\n",
    "    )\n",
    "\n",
    "    final_output: str = Field(default=\"\", description=\"최종 출력 결과\")\n",
    "\n",
    "\n",
    "# SinglePathPlanGenerationAgent (노드 함수 포함) 정의\n",
    "\n",
    "class SinglePathPlanGenerationAgent:\n",
    "\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "\n",
    "        self.llm = llm\n",
    "\n",
    "        self.passive_goal_creator = PassiveGoalCreator(llm=llm)\n",
    "\n",
    "        self.prompt_optimizer = PromptOptimizer(llm=llm)\n",
    "\n",
    "        self.response_optimizer = ResponseOptimizer(llm=llm)\n",
    "\n",
    "\n",
    "    def goal_setting(self, state: SinglePathPlanGenerationState) -> Dict[str, Any]:\n",
    "\n",
    "        goal: Goal = self.passive_goal_creator.run(query=state.query)\n",
    "\n",
    "        optimized_goal: OptimizedGoal = self.prompt_optimizer.run(query=goal.text)\n",
    "\n",
    "        optimized_response: str = self.response_optimizer.run(query=optimized_goal.text)\n",
    "\n",
    "        return {\n",
    "\n",
    "            \"optimized_goal\": optimized_goal.text,\n",
    "\n",
    "            \"optimized_response\": optimized_response,\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "# DecomposedTasks 데이터 모델 정의 (태스크 분해 결과)\n",
    "\n",
    "class DecomposedTasks(BaseModel):\n",
    "\n",
    "    values: List[str] = Field(\n",
    "\n",
    "        default_factory=list,\n",
    "\n",
    "        min_items=3,\n",
    "\n",
    "        max_items=5,\n",
    "\n",
    "        description=\"3~5개로 분해된 태스크\",\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "# QueryDecomposer 클래스 정의\n",
    "\n",
    "class QueryDecomposer:\n",
    "\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "\n",
    "        self.llm = llm\n",
    "\n",
    "        self.current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "    def run(self, query: str) -> DecomposedTasks:\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "\n",
    "            f\"\"\"CURRENT DATE: {self.current_date}\n",
    "\n",
    "\n",
    "태스크: 주어진 목표를 구체적이고 실행 가능한 태스크로 분해해 주세요.\n",
    "\n",
    "요건: \n",
    "\n",
    "1. 다음 행동만으로 목표를 달성할 것 절대 지정된 이외의 행동을 취하지 말 것.\n",
    "\n",
    " - 인터넷을 이용하여 목표 달성을 위한 조사를 수행한다.\n",
    "\n",
    " - 사용자를 위한 보고서를 생성한다.\n",
    "\n",
    "2. 각 태스크는 구체적이고 상세하게 기재하며, 단독으로 실행 및 검증 가능한 정보를 포함할 것. 추상적인 표현을 일절 포함하지 말 것.\n",
    "\n",
    "3. 태스크는 실행 가능한 순서로 리스트화할 것.\n",
    "\n",
    "4. 태스크는 한국어로 출력할 것.\n",
    "\n",
    "목표: {query}\"\"\"\n",
    "\n",
    "        )\n",
    "\n",
    "        chain = prompt | self.llm.with_structured_output(DecomposedTasks)\n",
    "\n",
    "        return chain.invoke({\"query\": query})\n",
    "\n",
    "\n",
    "    def _decompose_query(self, state: SinglePathPlanGenerationState) -> Dict[str, Any]:\n",
    "\n",
    "        decomposer = QueryDecomposer(llm=self.llm)\n",
    "\n",
    "        decomposed_tasks: DecomposedTasks = decomposer.run(query=state.optimized_goal)\n",
    "\n",
    "        return {\"tasks\": decomposed_tasks.values}\n",
    "\n",
    "\n",
    "# TaskExecutor 클래스 정의\n",
    "\n",
    "class TaskExecutor:\n",
    "\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "\n",
    "        self.llm = llm\n",
    "\n",
    "        self.tools = [TavilySearchResults(max_results=3)]\n",
    "\n",
    "\n",
    "    def run(self, task: str) -> str:\n",
    "\n",
    "        agent = create_react_agent(self.llm, self.tools)\n",
    "\n",
    "        result = agent.invoke(\n",
    "\n",
    "            {\n",
    "\n",
    "                \"messages\": [\n",
    "\n",
    "                    (\n",
    "\n",
    "                        \"human\",\n",
    "\n",
    "                        f\"\"\"다음 태스크를 실행하고 상세한 답변을 제공해 주세요.\n",
    "\n",
    "\n",
    "태스크: {task}\n",
    "\n",
    "\n",
    "요건:\n",
    "\n",
    "1. 필요에 따라 제공된 도구를 사용하세요.\n",
    "\n",
    "2. 실행은 철저하고 포괄적으로 수행하세요. \n",
    "\n",
    "3. 가능한 한 구체적인 사실이나 데이터를 제공하세요.\n",
    "\n",
    "4. 발견한 내용을 명확하게 요약하세요.\"\"\"\n",
    "\n",
    "                    )\n",
    "\n",
    "                ]\n",
    "\n",
    "            }\n",
    "\n",
    "        )\n",
    "\n",
    "        return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "    def _execute_task(self, state: SinglePathPlanGenerationState) -> Dict[str, Any]:\n",
    "\n",
    "        self.task_executor = TaskExecutor(llm=self.llm)\n",
    "\n",
    "        current_task = state.tasks[state.current_task_index]\n",
    "\n",
    "        result = self.task_executor.run(task=current_task)\n",
    "\n",
    "        return {\n",
    "\n",
    "            \"results\": [result],\n",
    "\n",
    "            \"current_task_index\": state.current_task_index + 1,\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "# ResultAggregator 클래스 정의\n",
    "\n",
    "class ResultAggregator:\n",
    "\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "\n",
    "        self.llm = llm\n",
    "\n",
    "\n",
    "    def run(self, query: str, response_definition: str, results: List[str]) -> str:\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "\n",
    "            \"\"\"주어진 목표:\n",
    "\n",
    "{query}\n",
    "\n",
    "\n",
    "조사 결과: \n",
    "\n",
    "{results}\n",
    "\n",
    "\n",
    "주어진 목표에 대해 조사 결과를 활용하여 다음 지시에 기반한 응답을 생성해 주세요.\n",
    "\n",
    "{response_definition}\"\"\"\n",
    "\n",
    "        )\n",
    "\n",
    "        results_str = \"\\n\\n\".join(\n",
    "\n",
    "            f\"Info {i+1}:\\n{result}\" for i, result in enumerate(results)\n",
    "\n",
    "        )\n",
    "\n",
    "        chain = prompt | self.llm | StrOutputParser()\n",
    "\n",
    "        return chain.invoke(\n",
    "\n",
    "            {\n",
    "\n",
    "                \"query\": query,\n",
    "\n",
    "                \"results\": results_str,\n",
    "\n",
    "                \"response_definition\": response_definition,\n",
    "\n",
    "            }\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "    def _aggregate_results(self, state: SinglePathPlanGenerationState) -> Dict[str, Any]:\n",
    "\n",
    "        self.result_aggregator = ResultAggregator(llm=self.llm)\n",
    "\n",
    "        final_output = self.result_aggregator.run(\n",
    "\n",
    "            query=state.optimized_goal,\n",
    "\n",
    "            response_definition=state.optimized_response,\n",
    "\n",
    "            results=state.results,\n",
    "\n",
    "        )\n",
    "\n",
    "        return {\"final_output\": final_output}\n",
    "\n",
    "\n",
    "# LangGraph 워크플로우 정의\n",
    "\n",
    "class SinglePathPlanGeneratorGraph:\n",
    "\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "\n",
    "        self.llm = llm\n",
    "\n",
    "        self.agent_nodes = SinglePathPlanGenerationAgent(llm)\n",
    "\n",
    "        self.query_decomposer_instance = QueryDecomposer(llm)\n",
    "\n",
    "        self.task_executor_instance = TaskExecutor(llm)\n",
    "\n",
    "        self.result_aggregator_instance = ResultAggregator(llm)\n",
    "\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        workflow = StateGraph(SinglePathPlanGenerationState)\n",
    "\n",
    "\n",
    "        workflow.add_node(\"goal_setting\", self.agent_nodes.goal_setting)\n",
    "\n",
    "        workflow.add_node(\"decompose_query\", self.query_decomposer_instance._decompose_query)\n",
    "\n",
    "        workflow.add_node(\"execute_task\", self.task_executor_instance._execute_task)\n",
    "\n",
    "        workflow.add_node(\"aggregate_results\", self.result_aggregator_instance._aggregate_results)\n",
    "\n",
    "\n",
    "        workflow.set_entry_point(\"goal_setting\")\n",
    "\n",
    "\n",
    "        workflow.add_edge(\"goal_setting\", \"decompose_query\")\n",
    "\n",
    "        workflow.add_edge(\"decompose_query\", \"execute_task\")\n",
    "\n",
    "\n",
    "        workflow.add_conditional_edges(\n",
    "\n",
    "            \"execute_task\",\n",
    "\n",
    "            lambda state: \"continue\" if state.current_task_index < len(state.tasks) else \"finish\",\n",
    "\n",
    "            {\n",
    "\n",
    "                \"continue\": \"execute_task\",\n",
    "\n",
    "                \"finish\": \"aggregate_results\",\n",
    "\n",
    "            },\n",
    "\n",
    "        )\n",
    "\n",
    "        workflow.add_edge(\"aggregate_results\", END)\n",
    "\n",
    "\n",
    "        return workflow.compile()\n",
    "\n",
    "\n",
    "# 싱글 패스 플랜 제너레이터 실행\n",
    "\n",
    "single_path_llm = ChatOpenAI(model=settings.openai_smart_model, temperature=settings.temperature)\n",
    "\n",
    "single_path_graph_builder = SinglePathPlanGeneratorGraph(llm=single_path_llm)\n",
    "\n",
    "single_path_app = single_path_graph_builder.build_graph()\n",
    "\n",
    "\n",
    "inputs = {\"query\": \"카레라이스 만드는 법\"}\n",
    "\n",
    "print(\"\\n--- 싱글 패스 플랜 제너레이터 실행 결과 ---\")\n",
    "\n",
    "for s in single_path_app.stream(inputs):\n",
    "\n",
    "    print(s)\n",
    "\n",
    "\n",
    "final_state = next(iter(single_path_app.stream(inputs, stream_mode=\"values\")))\n",
    "\n",
    "print(f\"\\n최종 보고서:\\n{final_state.get('final_output', '최종 출력이 없습니다.')}\")\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
