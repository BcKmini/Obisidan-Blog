# 0. 주제 다시 짚고가기

- 천안 도시재생센터와 협업, 실시간으로 빈집 현황을 파악가능한 트래킹 플랫폼 구현
- Data- 전기데이터, 수도 데이터 등

---

# 1. 현 빈집 현황 / 우리가 만들어야 할 필요성

![[지도1.png]]
![[지도2.png]]
![[빈집현황.png]]
출처 : [https://www.cctoday.co.kr/news/articleView.html?idxno=2196881](https://www.cctoday.co.kr/news/articleView.html?idxno=2196881)

출처 : [https://www.cctoday.co.kr/news/articleView.html?idxno=2158511](https://www.cctoday.co.kr/news/articleView.html?idxno=2158511)

출처 : [https://binzibe.kr/binzibe/binzibplatform/statisticInfo/binzibMap.do](https://binzibe.kr/binzibe/binzibplatform/statisticInfo/binzibMap.do) - (2024년도 충청남도 기준)

### 1.1 - 배경

전국적으로 빈집의 수는 지속적으로 증가(지방에 빈집 수는 크게 증가)하는 추세이며 , 이는 도시의 안전, 미관, 그리고 경제적 활력에 다각적인 부정적 영향을 미치고 있다. 방치된 빈집은 화재 발생 및 범죄 위험을 높이고, 주거 환경을 악화시키며, 부동산 가치 하락을 초래하여 지속 가능한 도시재생을 저해하는 핵심 요인이다.

### 1.2 - 필요성

1. 현재 빈집 현황 조사는 주로 현장 방문이나 주민 신고에 의존하고 있어 시간과 인력 소모가 크고, 실시간 변동 상황을 반영하기 어렵다.
    ![[빈집신고구조.png]]

- 출처 : [https://easylaw.go.kr/CSP/CnpClsMainBtr.laf?popMenu=ov&csmSeq=1772&ccfNo=2&cciNo=2&cnpClsNo=1](https://easylaw.go.kr/CSP/CnpClsMainBtr.laf?popMenu=ov&csmSeq=1772&ccfNo=2&cciNo=2&cnpClsNo=1)

1. 빈집은 도시 미관을 저해하고, 안전 문제(범죄, 화재 등)를 유발하며, 우범 지대로 변질될 가능성이 높다. 또한, 장기간 방치될 경우 건물 노후화가 가속화되어 재생 사업 비용을 증가시킬 수 있다.
![[화재.png]]
- 출처 : [https://news.kbs.co.kr/news/pc/view/view.do?ncd=7990423](https://news.kbs.co.kr/news/pc/view/view.do?ncd=7990423)

1. 정확한 빈집 정보는 단순한 공간 문제를 넘어선 다양한 사회적 문제 해결에 기여한다. 빈집 데이터는 청년 및 신혼부부에게 저렴한 주거 공간을 제공하거나, 예술가 작업실, 커뮤니티 공간 등으로 활용하는 등 다양한 형태의 빈집 활용 사업을 기획하는 데 중요한 근거가 된다.

![[빈집활용현황.png]]

- 출처 : [https://binzibe.kr/binzibe/binzibplatform/notification/bestCase.do?pageNum=1](https://binzibe.kr/binzibe/binzibplatform/notification/bestCase.do?pageNum=1) - 활용사례

---

# 2. 벤치마크 조사

|이니셔티브/플랫폼 명칭|주관 기관/도시|주요 기능|활용 데이터|현황/범위|
|---|---|---|---|---|
|빈집애(愛)|행정안전부 &||||
|한국부동산원|빈집 지도||||
|정비 실적 공개|||||
|활용 사례|||||
|정책 정보|||||
|거래 지원 서비스|||||
|(검토 중)|지자체 빈집 현황조사 결과, 행정 통계,||||
|(인구 감소, 사망률, 주택 노후도)|||||
|외부 데이터(생활 인프라, 유동 인구)|전국 단위||||
|울산 AI 예측형 솔루션|울산광역시|AI 기반 빈집 발생 예측|||
|최적 실태조사 경로 안내|||||
|도시 안전/미관 개선|주거용 에너지 데이터(도시가스, 전기, 수도)|시범 사업 후 확산|||
|(충북, 전북 등)|||||

### 한국부동산원 '빈집애(愛)' 누리집

- 데이터 출처 한국부동산원 (빈집애 플랫폼 운영), 각 지자체 (실태조사 데이터 제공)
- 데이터 내용
    - 빈집 주소, 위치 정보 (지도 기반)
    - 빈집으로 분류된 날짜 및 기간
    - 빈집 유형 (예: 장기 방치, 멸실 예정 등)
    - 건물 정보 (건축 연도, 구조, 면적 등)
    - 해당 지자체의 빈집 활용 계획 및 사업 현황
- 데이터 얻는 방법
    1. 공공데이터 연계 협약: 천안시가 한국부동산원과 공식적인 데이터 연계 및 활용 협약을 맺는 것이 가장 확실하고 신뢰성 있는 방법

→ 우리가 알아야할 점

천안시는 이처럼 이미 구축된 국가 단위의 빈집 데이터 허브를 활용할 수 있다. 자체적으로 모든 데이터를 수집하고 시스템을 구축하는 것보다, 국가 플랫폼과의 연동을 통해 데이터 수집 부담을 줄이고 데이터의 신뢰성을 확보할 수 있다.

우리 프로젝트가 빈집 현황 파악에 드는 초기 비용과 시간을 절감하고, 국가 표준에 맞는 데이터 관리 체계를 구축하는 데 기여할 것

---

# 3. 전기/수도 데이터 활용 빈집 거주 여부 판단 기준

|구분|판단 기준|
|---|---|
|전기|월별 사용량 10kWh 이하 (12개월 이상 지속)|
|전기|최근 12개월 사용량 합계 120kWh 이하|
|전기|전기 계량기 사용 중지 상태 (0kWh, 12개월 이상 지속)|
|전기|전기 계량기 철거된 경우|
|**수도**|월별 사용량 0.21㎥ (210ℓ) 미만 (12개월 이상 지속)|
|수도|월별 사용량 0㎥ (단수) (12개월 이상 지속)|

출처 : [https://www.easylaw.go.kr/CSP/CnpClsMainBtr.laf?popMenu=ov&csmSeq=1772&ccfNo=2&cciNo=2&cnpClsNo=1&menuType=onhunqna](https://www.easylaw.go.kr/CSP/CnpClsMainBtr.laf?popMenu=ov&csmSeq=1772&ccfNo=2&cciNo=2&cnpClsNo=1&menuType=onhunqna)

출처 : [https://www.seoulsolution.kr/sites/default/files/세계와도시 22호_특집2.pdf](https://www.seoulsolution.kr/sites/default/files/%EC%84%B8%EA%B3%84%EC%99%80%EB%8F%84%EC%8B%9C%2022%ED%98%B8_%ED%8A%B9%EC%A7%912.pdf)

- Data 이용 방법
    
    로우데이터 → 월합·평균 → 이상치 처리(누수/계량 오류) → 기준 판정 → 스코어링
    
    - 두 개 이상 지표(예: _전기 24kWh 미만_ + _수도 0.21㎥ 미만_) 동시 충족 시 빈집 신뢰도 가중
    - _월 10kWh 이하_ 같은 더 엄격한 기준은 우선 조사 대상(High Priority) 필터로 활용

---

## 4. 앞으로 계획

### 4.1 - 데이터 저장/관리 (MySQL) 및 협업 방안

MySQL은 우리 플랫폼의 모든 핵심 데이터(주소 정보, 전기/수도 사용량 시계열 데이터, AI 분석 결과, 빈집 상태, 사용자 정보 등)를 저장

1. 공용 개발용 MySQL 서버 구축 (필수)
    - 방법: 4명의 팀원이 각자의 로컬 환경에서 독립적으로 개발할 수도 있지만, 데이터의 일관성과 협업 효율을 위해 클라우드 기반의 공용 MySQL 서버를 구축
        - 서비스: AWS RDS (Amazon Relational Database Service)의 MySQL 인스턴스, Google Cloud SQL for MySQL, Azure Database for MySQL 등. 초기에는 소규모 인스턴스로 시작
        - 접근 방법: 선정된 클라우드 DB의 접속 정보(엔드포인트, 포트, 사용자명, 비밀번호)를 팀 내에서 공유
2. 데이터베이스 스키마(Schema) 설계 및 관리
    - 주도: 백엔드 팀(김범진, 김경민)이 주도하되, 프론트엔드 팀(조예림, 양상연) 및 AI 분석 담당자와 함께 협의하여 설계
    - 협의 내용:
        - 주요 테이블 (예시)
            - `houses` (주소, 건물 정보), `electricity_usage` (전기 사용량 시계열), `water_usage` (수도 사용량), `vacancy_status` (AI 분석 결과 및 빈집 상태), `users` (플랫폼 사용자 정보) 등을 포함할 수 있다.
        - 데이터 타입, 관계, 제약 조건
            - 각 필드의 자료형, 테이블 간의 관계(Foreign Key), NULL 허용 여부 등을 명확히 한다.
    - 설계 도구
        - `ERD (Entity-Relationship Diagram)` 툴 (예: `dbdiagram.io`, `draw.io`)을 사용하여 시각적으로 설계
    - 문서화
        - 설계된 ERD와 테이블 정의서는 Notion의 페이지에 상세히 문서화하고, 업데이트될 때마다 모든 팀원이 확인할 수 있도록 한다. (작업페이지 따로 구분)
    - 버전 관리:
        - DB 스키마 변경 사항은 `SQL 마이그레이션 도구` - ORM 마이그레이션 기능을 사용하여 관리
        - 모든 스키마 변경 스크립트(.sql 파일 등)는 GitHub 레포지토리의 `db_scripts/` 또는 `migrations/` 폴더에 저장하고, PR을 통해 리뷰 후 `develop` 브랜치에 병합 진행
3. 초기 데이터 적재 및 관리 (천안시 재생센터 협업 데이터):
    - 담당: 데이터 수집/확보를 담당하는 조예림, 김범진 님이 주도 (예시)
    - 방법:
        1. 데이터 전달 방식 협의: 천안시 재생센터와 전기/수도 데이터를 어떤 형식(CSV, JSON, DB 덤프 등)으로, 어떤 방식으로(SFTP, 보안 웹하드, 직접 전달 등) 받을지 구체적으로 협의한다. (보안 신경써야함)
        2. 데이터 전처리 스크립트 개발: 받은 데이터를 MySQL 스키마에 맞게 파싱하고 정제하는 Python 스크립트를 백엔드 팀이 개발. 이 스크립트는 GitHub에 `data_ingestion/ (가안)`폴더 등에 저장.
        3. 초기 데이터 적재: 전처리 스크립트를 사용하여 공용 개발 DB에 초기 데이터를 적재. (백엔드 팀이 담당)
    - 지속적인 데이터 연동: 실시간/근실시간 트래킹을 위해서는 전기/수도 데이터를 정기적으로 자동 수집하여 DB에 업데이트하는 파이프라인을 구축 해야함

---

### 4.2- AI 분석 방안

AI 분석은 주로 백엔드에서 데이터 처리 및 모델 학습/추론을 담당하게 됩니다.

1. AI 분석 목표:
    - 빈집 여부 판단
        - 전기/수도 사용량 패턴(예: 장기간 사용량 0, 특정 임계치 이하 지속)을 기반으로 해당 주택이 빈집인지 아닌지를 판단. (3번 참고해서 우리만의 기준을 다시 확립해야함)
    - 빈집 위험도 예측
        - 과거 데이터 및 외부 요인(건축물 노후도, 주변 환경 등)을 학습하여 특정 주택이 미래에 빈집이 될 가능성을 예측.
    - 이상 탐지
        - 평소와 다른 사용량 패턴(예: 거주 중인 것처럼 보였으나 갑자기 장기 미사용)을 감지하여 분류/알림기능.
2. AI 모델 개발 (협의 필요)
3. 개발 환경 및 라이브러리:
    - 언어: Python (예시)
        - 주요 라이브러리: `Pandas`, `Numpy` (데이터 처리), `Scikit-learn` (기본 머신러닝 모델), `TensorFlow` 또는 `PyTorch` (딥러닝 모델 - 시계열 예측/분류에 필요시), `Matplotlib`/`Seaborn` (데이터 시각화).
    - 개발 환경
        - `Jupyter Notebook/Lab` (모델 프로토타이핑, 실험), `VS Code` (최종 모델 코드 작성 및 모듈화).
4. AI 모델 연동:
    - FastAPI 활용 시
        - Python으로 개발된 AI 모델을 FastAPI 백엔드에서 직접 불러와 추론(Inference)을 수행
    - Node.js/Spring 활용 시
        - AI 모델을 별도의 마이크로서비스로 분리하거나, Node.js에서 Python 스크립트를 호출하는 방식을 고려
5. AI 분석 파이프라인:
    - 정기적으로(예: 매일 자정) 백엔드에서 MySQL의 최신 데이터를 가져와 AI 모델에 입
    - AI 모델은 분석 결과를 생성하고, 이 결과를 다시 MySQL DB의 `vacancy_status` 테이블 등에 업데이트합니다.
    - `백엔드 스케줄링 모듈`(예: Node.js의 `node-cron`, Spring의 `Scheduler`)을 사용하여 이 과정을 자동화합니다.

---

### 4.3 - 백엔드 개발 협업 방안

백엔드는 프론트엔드와 DB, AI 모델을 연결하는 핵심 로직을 담당.

1. 프레임워크 선택:
    - 세 가지 중 하나를 메인으로 선택 해야함
        - FastAPI (Python): AI 모델(Python)과의 통합이 매우 강력하고, 빠르고 가벼워 초기 개발에 유리하다. (비동기 처리에 강함)
        - Node.js (JavaScript): 프론트엔드(React)와 언어 통일성이 있어 팀원 간 코드 이해도가 높고, 비동기 처리에 능숙 (사용한 경험이 있는 사람이 있음)
        - Spring (Java): 강력한 안정성과 다양한 기능을 제공하지만, 학습 곡선이 높고 개발 속도가 상대적으로 느릴 수 있다. (사용한 경험이 있는 사람이 있음)
    - 권장: FastAPI를 메인 백엔드로 하여 AI 모델 연동을 최적화하고, 웹 API를 제공하는 것이 현재 프로젝트 성격에 가장 적합할 수 있다.
2. API 명세서 작성 (프론트엔드와 협의)
    - 주도: 백엔드 팀(김범진, 김경민)
    - 협의
        - 프론트엔드 팀(조예림, 양상연)과 어떤 데이터를 주고받을지, 어떤 엔드포인트(URL)를 사용할지, 요청/응답 형식(JSON 등)을 명확히 정의
    - 도구
        - `Notion`에 상세히 작성하고, `Swagger/OpenAPI` (FastAPI는 /docs에서 볼 수 있음)를 활용하여 API 문서를 자동화 → 프론트엔드팀에 개발 전달
3. 모듈 분담 및 개발 (예시)
    - 김범진:
        - 데이터 연동 모듈: 전기/수도 데이터 수집 및 전처리 로직 구현, DB 적재.
        - AI 모델 연동 모듈: AI 모델을 백엔드에서 호출하고 결과를 받아오는 로직.
        - 데이터 CRUD API: DB에서 데이터를 조회, 생성, 수정, 삭제하는 기본 API 구현.
    - 김경민:
        - 인증/인가 모듈: 사용자(천안시 담당자) 로그인, 토큰 관리, 권한 확인.
        - 메인 API 엔드포인트 구현: 프론트엔드에서 요구하는 복합적인 데이터를 가공하여 제공하는 API.
        - 스케줄링/알림 모듈: AI 분석 주기 관리, 특정 조건(새 빈집 감지 등) 시 알림 발송.
    - 코드 리뷰: GitHUb Pull Request를 통해 코드를 리뷰하고 피드백을 주고 받는다.

---

### 4.4 - 프론트엔드 시각화 협업 방안

사용자가 플랫폼을 통해 빈집 현황을 직관적으로 파악할 수 있도록 시각화에 집중

1. UI/UX 디자인 및 와이어프레임:
    - 주도: 프론트엔드 팀(조예림, 양상연)
    - 협의
        - 백엔드 팀 및 '발표자'와 플랫폼의 전체적인 레이아웃, 핵심 기능 배치, 사용자 흐름에 대해 협의
    - 도구
        - `Figma`나 `Protopie`와 같은 디자인 툴을 활용해서 만든 후 Notion에 공유하여 피드백 진행 → 수정 → 진행 → 수정 → 완료
2. React 컴포넌트 기반 개발:
    - 컴포넌트 분리: 재사용 가능한 UI 요소(버튼, 카드, 헤더, 푸터, 지도 컴포넌트, 차트 컴포넌트 등)를 독립적인 React 컴포넌트로 분리하여 개발
    - 작업 분담 (예시)
        - 조예림:
            - 메인 대시보드 구현: 전체 빈집 현황, AI 예측 통계 등 주요 지표 시각화 (차트 라이브러리 연동: `Recharts` 또는 `Chart.js`).
            - 지도 기반 빈집 트래킹 구현: 지도 API(카카오맵, 네이버맵 등) 연동, 빈집 위치 표시, 위험도별 색상 구분, 클러스터링 등.
        - 양상연:
            - 개별 주택 상세 정보 페이지: 특정 주택 클릭 시 전기/수도 사용량 시계열 그래프, AI 판단 이력, 현장 조사 기록 등을 상세히 표시.
            - 인증/관리 페이지: 로그인, 사용자 관리, 시스템 설정 등 관리자 기능 UI 구현.
    - API 연동
        - API 명세서에 따라 데이터를 요청하고 받아와 화면에 렌더링 (`Axios`나 `fetch API`를 활용)
    - 상태 관리
        - `React Context API` 또는 `Redux` 같은 전역 상태 관리 라이브러리를 사용하여 여러 컴포넌트가 공유해야 하는 데이터(예: 로그인 상태, 전체 빈집 목록)를 효율적으로 관리

---

### 4.5. GitHub 조직 및 협업 방식 (모든 팀원)

1. GitHub Organization 생성 (진행완료 - [Github](https://github.com/KT-TeamProject-11))
2. 레포지토리(Repository) 구조
    - 하나의 Organization 내에 여러개의 레포지토리 생성 예정 (예: `Frontend, Backend, Ai_model, ..` ).
    - 이 레포지토리 안에 각 브렌치별로 구분하여 관리 예정
3. 브랜치 전략
    - `main` 브랜치: 항상 안정적이고 배포 가능한 최종 결과물 상태를 유지합니다. 절대 직접 커밋하지 않습니다.
    - `develop` 브랜치: 통합 개발 브랜치입니다. 모든 팀원의 기능 개발이 완료되면 이 브랜치로 병합
    - `feature` 브랜치: 각 팀원이 새로운 기능을 개발할 때 `develop` 브랜치에서 분기(branch)하여 생성 (예: `feature/fe-dashboard-chart`, `feature/be-ai-integration`).
    - `bugfix` 브랜치: 버그 수정 시 `develop` 또는 `main`에서 분기하여 생성합니다.
4. Pull Request (PR) 기반 코드 리뷰:
    - 작업 흐름:
        1. 자신의 `feature` 브랜치에서 개발을 진행
        2. 개발이 완료되면 `develop` 브랜치로 `Pull Request (PR)`를 생성
        3. PR 생성 시, 변경 내용, 목적, 테스트 방법 등을 명확하게 작성 해야한다.
        4. 다른 팀원(특히 관련 담당자)을 Reviewer로 지정 → 1명 이상이 리뷰를 하도록 규칙을 정한다.
        5. 리뷰어는 코드의 품질, 기능의 정확성, 잠재적 문제점 등을 검토하고 피드백을 제공
        6. 피드백을 반영하여 코드를 수정하고, 리뷰어가 승인(Approve)하면 `develop` 브랜치로 병합(Merge)
5. 커밋 메시지 규칙 (컨벤션 참고)
    - 일관된 커밋 메시지 규칙을 정하여 적용합니다. (예: Angular Convention)
    - `feat: 로그인 기능 구현 및 API 연동` (새 기능 추가)
    - `fix: 지도 컴포넌트 마커 표시 오류 수정` (버그 수정)
    - `docs: DB 스키마 ERD 업데이트` (문서 변경)
    - `refactor: 백엔드 모듈 코드 리팩토링` (코드 구조 개선, 기능 변경 없음)
    - `chore: 개발 환경 설정 파일 추가` (자잘한 작업)
6. GitHub Issues (태스크 (디스코드) 관리):
    - 각 주간회의 마다 GitHub Issues or 디크코드를 사용하여 각 기능, 버그, 개선사항 등을 태스크로 등록하고 팀원에게 할당
    - 진행 상황(To Do, In Progress, Done)을 노션에 업데이트
    - 깃허브 PR과 연동하여 해당 PR이 어떤 Issue를 해결했는지 명시