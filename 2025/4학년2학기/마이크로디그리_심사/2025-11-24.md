## 0. 내 상황 정리

- 학교: 건국대학교 글로컬캠퍼스 컴퓨터공학과 4학년
- 트랙: Microdegree (인공지능 전문가 양성과정)
- 수강 과목
  - 인공지능기초
  - 기계학습
  - 딥러닝
  - 클라우드컴퓨팅
  - Nanolab (Gemini, Codex 활용 바이브 코딩 수업)
- 현재 할 일
  - Microdegree 수료를 위해 **심사요지 + 연구 방향** 보고서 작성
  - Computer Vision(CV) 분야로 주제를 가져가고 싶음
  - 단순한 CIFAR-10 분류가 아니라, **조금 더 연구 느낌**이 나는 방향을 원함

- 최종 선택한 큰 방향
  - **A: CNN vs ViT 비교**
  - **B: Clean vs Corrupted(robustness) 비교**
  - → 둘을 합쳐서 연구 주제로 설정
---
## 1. 연구 주제(가제) 정리

- 가제 1  
  - `Vision Transformer와 CNN의 데이터 효율성과 강인성 비교 연구: 깨끗한 이미지와 손상된 이미지 실험 기반 분석`

- 가제 2  
  - `CNN과 Vision Transformer의 데이터 효율성 및 Robustness 비교: CIFAR-10과 Corruption 데이터셋을 이용한 실험`

- 향후 교수님 피드백에 따라
  - 제목 길이 줄이기
  - “데이터 효율성” / “강인성(robustness)” 중 어디에 더 비중을 둘지 조정 예정

---
## 2. 연구 배경 및 Motivation 정리용 뼈대

- Computer Vision에서 사용되는 대표적인 모델 계열
  - **CNN 계열**
  - **Transformer 기반 Vision Transformer(ViT)** 계열
- 실제 환경의 이미지 특징
  - 센서 노이즈, 블러, 조명 변화, 날씨 효과 등으로 인해 **이미지가 깨끗하지 않은 경우가 많음**
  - 모델이 **깨끗한 이미지에서만 잘 동작하는 것**이 아니라,
    **손상된/변형된 이미지에서도 안정적으로 동작하는지(robustness)가 중요
- 학부 4학년 + Microdegree 수준에서의 목표
  - “새로운 알고리즘을 제안”하는 것이 아니라,
  - **기존 대표 모델(CNN, ViT)을 선택하고
  - **데이터 양과 이미지 손상 정도에 따라 성능과 특성을 분석**하는 형태의 연구
- 이 연구를 통해 보고 싶은 것
  - 데이터가 충분하지 않을 때 **CNN vs ViT의 성능 차이**
  - 다양한 corruption(노이즈, 블러 등)이 있을 때 **두 모델의 강인성 차이**
  - 수업에서 배운 **일반화, 과적합, 표현력** 개념과 연결해서 해석

---

## 3. 연구 질문(Research Questions) 뼈대

- RQ1  
  - 학습 데이터 양이 줄어들 때,  
    **CNN과 Vision Transformer의 성능(정확도, 손실)은 각각 어떻게 변화하는가?**

- RQ2  
  - 깨끗한(clean) 테스트 이미지와  
    다양한 corruption(노이즈, 블러 등)이 적용된 테스트 이미지에서,  
    **CNN과 Vision Transformer의 성능 저하 양상은 어떻게 다른가?**

- RQ3 (선택적으로 추가 가능)  
  - 데이터 증강(augmentation) 또는 간단한 학습 설정 변경에 따라  
    **각 모델의 robustness가 얼마나 개선되는가?**

---

## 4. 연구 방법(Methodology) 구조

### 4.1. 데이터셋

- 기본 데이터셋
  - 예: **CIFAR-10**
    - 10개 클래스의 컬러 이미지(32x32)
- 손상된 이미지 데이터셋(robustness 평가용)
  - 예: **CIFAR-10-C** 또는 그와 유사한 corruption 데이터셋
    - 노이즈, 블러, 날씨 효과 등의 변형이 적용된 버전
  - 사용할 corruption 타입/강도는 범위 조절 가능
    - 예: Gaussian noise, motion blur, brightness 변화 등 선택

### 4.2. 모델

- CNN 계열
  - 예: ResNet-18 또는 작은 커스텀 CNN
  - 특징: 전통적인 convolution 기반 구조
- Vision Transformer(ViT) 계열
  - 예: 공개된 pretrained ViT 모델을 가져와 fine-tuning
  - 특징: 이미지를 패치로 쪼개서 Transformer로 처리하는 구조

### 4.3. 실험 설계

1) **데이터 효율성 실험**
   - 동일한 데이터셋(CIFAR-10)에 대해
     - 학습 데이터 비율을 조절
       - 100%, 50%, 20%, 10% 등
   - 각 비율에 대해
     - CNN 학습 → test 성능 측정
     - ViT 학습(fine-tuning) → test 성능 측정
   - 비교 포인트
     - 데이터가 줄어들수록 성능이 어떻게 떨어지는지
     - 어떤 모델이 데이터 부족 상황에서 더 잘 버티는지

2) **Robustness(강인성) 실험**
   - 깨끗한(clean) 테스트 셋 vs 손상된(corrupted) 테스트 셋
     - 같은 모델에 대해 두 환경 모두에서 평가
   - 모델별로 측정
     - CNN: clean accuracy, corrupted accuracy
     - ViT: clean accuracy, corrupted accuracy
   - corruption 타입/강도에 따른 성능 변화 곡선 관찰
   - 분석 관점
     - 특정 corruption(예: 노이즈, 블러)에 특히 취약한 모델 계열이 있는지
     - CNN과 ViT 중 어느 쪽이 corruption에 상대적으로 강한지

3) (선택) 추가 실험 아이디어
   - 간단한 데이터 증강(on/off)을 비교
   - 학습 epoch, learning rate 등 하이퍼파라미터를 가볍게 바꿔보며 안정성 확인

### 4.4. 분석 및 해석

- 데이터 효율성 관점
  - 데이터가 부족할 때 나타나는 과적합, 일반화 성능 차이
- Robustness 관점
  - corruption 수준/타입에 따른 성능 저하 패턴
  - “현실적인 상황”에서 어떤 모델이 유리할지에 대한 논의
- 이론 연결
  - 수업에서 배운 일반화, bias-variance, 표현력, inductive bias 등과 연결해서 서술

---
## 5. 코드/실험 방향 메모(스니펫 설계용)

> 실제 코드는 나중에 직접 작성/수정하면서 채워 넣기

- 데이터 로더 구성
  - CIFAR-10 train/test 로드
  - CIFAR-10-C(또는 비슷한 corruption 데이터) 로드
- 모델 정의
  - `SimpleCNN` or `ResNet18`
  - `ViT` (timm / huggingface 등 활용)
- 공통 학습 루프
  - `train(model, train_loader, optimizer, epochs, ...)`
  - `evaluate(model, test_loader)` → accuracy, loss
- 실험을 함수 단위로 쪼개기
  - `run_experiment(data_ratio, model_type, ...)`
  - `run_robustness_test(model, corrupted_loader, ...)`
- 결과 정리
  - ratio 별 성능 딕셔너리/CSV 저장
  - clean vs corrupted 성능 비교 표/그래프