### **3D Vision 공부: 투영 행렬 (Projection Matrix) 쉽게 이해하기**

우리가 카메라로 사진을 찍는다고 생각해봅시다. 실제 3차원 세상에 있는 물체들(나무, 사람, 자동차 등)이 카메라 렌즈를 통과해서 2차원 사진으로 기록되죠. 이 과정을 **'투영(Projection)'**이라고 합니다.

이 블로그 글은 3차원 세상을 2차원 사진으로 바꾸는 데 필요한 중요한 개념과 계산 방식을 설명하고 있습니다.

---

#### **핵심 개념: 왜 '월드 좌표계'가 필요할까요?**

**1. 카메라 내부 파라미터 (K): 카메라 자체의 눈**

- 카메라 자체의 눈이라고 생각하면 편합니다. 사진을 찍는 카메라 렌즈의 특성, 센서의 위치 같은 고유한 정보들이에요.
    
- **초점 거리 (f_x, f_y):** 렌즈와 센서 사이의 거리입니다. 이게 길면 멀리 있는 것도 크게 찍히죠.
    
- **주점 (c_x, c_y):** 이미지 센서의 정중앙 지점입니다.
    
- **왜곡 계수 (Distortion Coefficients):** 렌즈는 완벽하지 않아서 사진이 휘어 보이는 현상(왜곡)이 생겨요. 이 왜곡을 얼마나, 어떻게 보정해야 하는지 알려주는 값입니다. (예: 사진 가장자리가 둥글게 휘는 현상)
    
- 이 K 행렬은 3차원 공간의 한 점이 카메라 센서의 2차원 픽셀 어디에 맺힐지를 계산하는 데 사용됩니다.
    

**2. 월드 좌표계의 등장: 모두가 동의하는 '기준점'**

- **문제점:** 만약 카메라가 한 대뿐이라면, 카메라가 바라보는 방향을 기준으로 '여기가 (0,0,0)이야'라고 정할 수 있어요. 이걸 **카메라 좌표계**라고 합니다.
    
- **여러 카메라:** 하지만 카메라가 여러 대이고, 각기 다른 위치와 방향에서 같은 장면을 찍는다면 어떨까요? 각 카메라마다 자기 기준의 (0,0,0)이 생기겠죠? 그림 3처럼요. 그러면 같은 타일이라도 카메라1 기준으로는 (10,5,2)인데, 카메라2 기준으로는 (-3,8,1)이 될 수 있어요. 이러면 어떤 점이 실제 공간에서 같은 점인지 알기 어렵고, 카메라들 간의 관계도 파악하기 힘들어요.
    
- **해결책:** 이 문제를 해결하기 위해 **'월드 좌표계(World Coordinates)'**라는 새로운 기준을 도입합니다 (그림 4). 월드 좌표계는 마치 지구의 경도, 위도, 고도처럼, 모든 카메라와 물체가 동의하는 **절대적인 기준점**이에요. 이제 모든 카메라와 물체는 이 월드 좌표계를 기준으로 자신의 위치와 방향을 설명하게 됩니다.
    

**3. 좌표계 변환: 위치와 방향 바꾸기**

- 월드 좌표계를 도입하면, 3차원 공간의 물체가 사진으로 투영되는 과정이 한 단계 더 추가됩니다:
    
    1. **월드 좌표계 → 카메라 좌표계 변환:** 물체의 월드 좌표계 위치를 카메라의 관점으로 변환합니다. (내가 카메라를 들고 어디에 서서, 어느 방향을 바라보고 있는지에 따라 물체의 상대적인 위치가 달라지겠죠?)
        
    2. **카메라 좌표계 → 픽셀 좌표계 투영:** 변환된 물체의 카메라 좌표를 `K` 행렬을 이용해 2차원 이미지의 픽셀 위치로 바꿉니다.
        
- **축의 회전과 이동:**
    
    - **회전 (Rotation):** 카메라가 월드 좌표계에서 어느 방향을 바라보고 있는지 (돌아있는지)를 나타냅니다. 예를 들어, 카메라가 90도 오른쪽으로 돌려져 있다면, 월드 좌표계의 X축이 카메라 좌표계에서는 Y축처럼 보일 수 있겠죠. 재미있는 점은, 축이 회전하면 그 축에 대한 점의 상대적인 위치는 **반대 방향으로 회전**하는 것처럼 보인다는 겁니다 (그림 7).
        
    - **이동 (Translation):** 카메라가 월드 좌표계의 원점으로부터 얼마나 떨어져 있는지 (움직였는지)를 나타냅니다.
        
- 이러한 회전과 이동을 합쳐서 `[R|t]` 행렬로 표현합니다. 여기서 `R`은 회전 행렬, `t`는 이동 벡터입니다. 이 `[R|t]` 행렬을 **카메라 외부 파라미터 (Extrinsic Parameters)**라고 부릅니다.
    

**4. 투영 행렬 (Projection Matrix / Camera Matrix): 모든 것을 합치다**

- 결론적으로, 3차원 월드 좌표계의 한 점이 2차원 이미지의 픽셀로 변환되는 전체 과정은 두 가지 행렬의 곱으로 표현됩니다 (그림 17, 19):
    
    - **K (내부 파라미터):** 카메라 자체의 눈.
        
    - **[R|t] (외부 파라미터):** 카메라가 월드에서 어디에 있고 어디를 바라보는지.
        
- 이 두 행렬을 합친 $\text{P} = \text{K[R|t]}$를 **투영 행렬(Projection Matrix)** 또는 **카메라 행렬(Camera Matrix)**이라고 부릅니다.
    

---

#### **가장 중요한 '깊이(Depth)'!**

블로그 글에서도 강조하듯이, 2차원 이미지만으로는 3차원 깊이(Depth, Z 값)를 절대 알 수 없습니다. 사진에서 똑같은 크기로 보이는 두 사람이라도, 한 명은 가까이 있는 작은 아이일 수도 있고, 다른 한 명은 멀리 있는 큰 성인일 수도 있기 때문입니다.

깊이 정보를 얻는 방법은 여러 가지가 있습니다:

- **스테레오 카메라:** 사람의 두 눈처럼, 두 대의 카메라로 동시에 찍어서 두 이미지 간의 차이를 분석하여 깊이를 계산합니다.
    
- **Depth 카메라:** 적외선 등을 쏴서 물체까지의 거리를 직접 측정하는 카메라입니다 (예: 폰의 ToF 센서, 키넥트).
    
- **단안 카메라 (우리가 사용하는 Reolink Go Plus 같은 카메라):**
    
    - **객체의 실제 크기 이용:** 우리가 사용하는 방식입니다! 물체의 실제 크기(예: 고니 날개 폭 2.5m)를 미리 알고 있고, 이미지에서 그 물체가 몇 픽셀 크기로 보이는지를 측정하면, 카메라와 물체 사이의 거리를 추정할 수 있습니다 (삼각비 원리).
        
    - **AI 기반 깊이 추정:** 딥러닝 모델이 단일 이미지에서 깊이를 추정하도록 학습시키는 방법도 있지만, 정확도가 환경에 따라 달라질 수 있습니다.
        

---

**요약하자면,** 이 블로그 글은 3D 컴퓨터 비전에서 가장 기본적인 '3차원 → 2차원 투영' 과정을 이해하기 위한 핵심 요소들 (카메라 내부/외부 파라미터, 월드 좌표계, 투영 행렬)을 그림과 함께 자세히 설명하고 있습니다. 그리고 우리가 지금 구현하고 있는 "단안 카메라로 객체의 실제 크기를 이용해 3D 좌표를 추정하는 방식"의 이론적 배경이 되는 내용을 다루고 있습니다.